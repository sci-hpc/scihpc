{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Accelerate your computation","text":""},{"location":"blog/","title":"Blog","text":""},{"location":"blog/2024/07/07/installing-and-running-bhac-code-on-scicluster/","title":"Installing and running BHAC code on Scicluster","text":"<p> link to paper</p> <p>BHAC (the Black Hole Accretion Code) is a multidimensional general relativistic magnetohydrodynamics code based on the MPI-AMRVACframework. BHAC solves the equations of ideal general  relativistic magnetohydrodynamics in one, two or three dimensions on arbitrary stationary space-times, using an efficient block based approach.</p> <p>See here to learn how to run this code on Scicluster.</p>"},{"location":"blog/2024/05/16/new-webpage-for-scicluster/","title":"New webpage for Scicluster","text":"<p>OK! Finally I found some time to work on a new webpage for Scicluster. I built this webpage using Mkdocs and mkdocs-material. I hope we can continue adding useful contents that help to learn HPC better and use Scicluster more efficiently.</p>"},{"location":"docs/","title":"Scicluster Documentation","text":"<p>This is the documentation homepage. If you are new to cluster computing, please check out the following sections:</p> <ul> <li> <p>About Scicluster</p> </li> <li> <p>Getting started</p> </li> </ul>"},{"location":"docs/about/about-scicluster/","title":"About Scicluster","text":""},{"location":"docs/about/about-scicluster/#a-gnulinux-cluster-one-machine-consisting-of-many-machines","title":"A Gnu/Linux Cluster - one machine, consisting of many machines","text":"<p>On one hand you can look at Gnu/Linux clusters as rather large and powerful supercomputers, but on the other hand you can look at them as just a large bunch of servers and some storage system(s) connected with each other through a (high speed) network. Both of these views are fully correct, and it's therefore important to be aware of the strengths and the limitations of such a system.</p> <p></p>"},{"location":"docs/about/about-scicluster/#rocks-gnulinux-operating-system","title":"Rocks Gnu/Linux operating system","text":"<p>Scicluster is build upon Rocks version 7 cluster distribution. Rocks is an open-source Gnu/Linux cluster distribution based upon CentOS 7.4 that enables end users to easily build computational clusters. Hundreds of researchers from around the world have used Rocks to deploy their own clusters.</p>"},{"location":"docs/about/about-scicluster/#resource-description","title":"Resource description","text":"<p>Key info about any cluster including Scicluster are compute nodes, interconnection network, operating system and storage configuration.</p>"},{"location":"docs/about/about-scicluster/#node-info","title":"Node info","text":"Name CPU/GPU architecture # cores RAM (GB) Model sci (the head/login node) 2 x Xeon E5-2420 Ivy Bridge EN (2012) 2 x 6 16 Supermicro compute-0-0 <p>2 x Xeon E5-2630</p> <p>Quadro P4000</p> <p>Broadwell (2014)</p> <p>Pascal (2016)</p> <p>2 x 10</p> <p>1792</p> <p>64</p> <p>8</p> ML350-Gen9 compute-0-1 2 x Xeon E5-2695 Broadwell (2014) 2 x 18 64 DL360-Gen9 compute-0-2 2 x Xeon E5-2690 Haswell (2013) 2 x 12 256 DL380-Gen9 compute-0-3 <p>2 x Xeon E5-2695</p> <p>Tesla K80</p> <p>Broadwell (2014)</p> <p>Kepler (2014)</p> <p>2 x 18</p> <p>4992</p> <p>64</p> <p>24</p> DL380-Gen9"},{"location":"docs/about/about-scicluster/#networks","title":"Networks","text":"<p>Currently all nodes are connected with a 1 Gb ethernet network for IO/management as well as a 10 Gb low latency one for message passing (see the above figure).</p>"},{"location":"docs/about/about-scicluster/#os","title":"OS","text":"<p>CentOS 7.4</p>"},{"location":"docs/about/about-scicluster/#storage","title":"Storage","text":"<ul> <li>Scratch space ~ 4.8 TB local high speed disk (1.2 TB on each compute node)</li> <li>Shared space ~ 24 TB network file system (NFS) installed on the head node</li> </ul> <p>For more details see Storage section.</p>"},{"location":"docs/about/getting-started/","title":"Getting started","text":"<p>Here you will find the basics to work with Scicluster.</p>"},{"location":"docs/about/getting-started/#get-an-account","title":"Get an account","text":"<p>If you are associated with the Faculty of Science, Ferdowsi University of Mashhad, you may apply locally, otherwise please contact us.</p>"},{"location":"docs/about/getting-started/#connect-to-scicluster","title":"Connect to Scicluster","text":"<p>Please connect to the VPN address provided to you. Then you may connect to Scicluster login/head/frontend node via SSH into the login-node. This means that on Gnu/Linux and OSX you may directly connect by opening a terminal and writing <code>ssh your_username@login-node</code>. From Windows, you may connect via termius PuTTY or MobaXterm software. X-forwarding for graphical applications is also possible. Please see the login section for details.</p>"},{"location":"docs/about/getting-started/#on-nodes-and-files","title":"On nodes and files","text":"<p>When you login, you will be on the frontend node. Please do not run any long-lasting programs here. The frontend should only be used for job preparation (see below), internet access and simple file operations.</p> <p>You will also be in your home directory <code>/home/username</code>. Here, you have ~ 4.5 GB at your disposal with everyday backup. For actual work, please use the work area at <code>/work8</code>. It is better to make a directory with your username (if it is not made by admin for you) as</p> <pre><code>mkdir /work8/$USER\n</code></pre> <p>The quota for <code>/work8</code> is 375 GB. This space is not backed up, but it has a good performance. Please remove old files regularly (see the storage section). There are also two high performance storages <code>fortitude8</code> and <code>gratitude8</code> that you must contact administrator to apply for.</p> <p>To move files from your computer to Scicluster or vice versa, you may use any tool that works with ssh. On Linux and OSX, these are scp, rsync, or similar programs. On Windows, you may use WinSCP. You can also use our web portal.</p>"},{"location":"docs/about/getting-started/#run-a-program","title":"Run a program","text":"<p>There are many programs and libraries pre-installed. You may get a list of all programs by typing <code>module avail</code>. When you find your program of choice, you may load it using <code>module load</code>. You can also compile your own software, if necessary (see the module and compile sections). </p> <p>To eventually run the program, you have to write a job script. In this script, you can define how long the job (i.e. the program) will run and how much memory and compute cores it needs. For the actual computation, you need to learn at least the basics of Linux shell scripting.</p> <p>When you wrote the job script, you can start it with <code>sbatch jobscript.sh</code>. This will put the script in the queue, where it will wait until an appropriate compute node is available. You can see the status of your job with <code>squeue -u $USER</code>. Please see Batch and Job script examples sections.</p>"},{"location":"docs/about/getting-started/#get-help","title":"Get help","text":"<p>Do you need help with Scicluster? Contact us via scihpc@um.ac.ir. You can also request new software (either an update or entirely new software), suggest changes to this documentation, or send us any other suggestions or issues concerning Scicluster to that email address. Please also read the rest of this documentation.</p> <p>Happy computing!</p>"},{"location":"docs/about/login/","title":"Logging in for the first time","text":""},{"location":"docs/about/login/#connect-to-the-vpn","title":"Connect to the VPN","text":"<p>Before connecting to the Scicluster login node (currently our frontend node is also the login node), you need to first connect to the VPN. Please do as follow for your preferred OS:</p>"},{"location":"docs/about/login/#gnulinux-and-mac","title":"Gnu/Linux and Mac","text":"<ul> <li>install openfortivpn package. For example for ubuntu-based distros:</li> </ul> <pre><code>sudo apt install openfortivpn\n</code></pre> <ul> <li>open your editor and input the VPN information provided to you as:</li> </ul> <pre><code>host = \nport =\nusername = \npassword = \n</code></pre> <ul> <li> <p>save the file e.g. in your home as <code>my_vpn.conf</code>.</p> </li> <li> <p>run in the terminal:</p> </li> </ul> <pre><code>sudo openfortivpn -c ~/my_vpn.conf\n</code></pre> <ul> <li>enter your local (not the cluster) password and connect.</li> </ul>"},{"location":"docs/about/login/#windows","title":"Windows","text":"<p>Please go to this link and download the client for your OS version. Please read the user guide before installing FortiClient VPN.</p>"},{"location":"docs/about/login/#android","title":"Android","text":"<p>Please download the app via Google Play or Myket.</p>"},{"location":"docs/about/login/#log-in-with-ssh","title":"Log in with SSH","text":"<p>An SSH (Secure SHell) client is required to connect to sciscluster. An SSH client provides secure encrypted communications between two hosts over an insecure network.</p> <p>If you already have ssh installed on your UNIX-like system, login may be as easy as typing</p> <pre><code>ssh &lt;username&gt;@login-node\n</code></pre> <p>into a terminal window. Note you must replace login-node with the IP provided to you.</p>"},{"location":"docs/about/login/#log-in-with-an-ssh-key","title":"Log in with an ssh key","text":"<p>To avoid entering your password every time you log in and to increase security, you can log in with an ssh keypair. This keypair consists of a private key that you have to store on your computer and a public key that you can store on sciscluster. On Linux or OSX simply type:</p> <pre><code>ssh-keygen\n</code></pre> <p>and follow the instructions on the screen. Please use a good passphrase. You will have to enter this passphrase the first time you log in after a reboot of the computer, but not anymore afterwards. To copy the public key to sciscluster, type:</p> <pre><code>ssh-copy-id username@login-node\n</code></pre> <p>To learn more about ssh keys, have a look at this page.</p> <p>On Windows, you can use PuTTYgen that comes with PuTTY. More information on ssh.com.</p>"},{"location":"docs/about/login/#ssh-clients-for-windows-and-mac","title":"SSH clients for Windows and Mac","text":"<p>At the OpenSSH page you will find several SSH alternatives for both Windows and Mac.</p> <p>Please note that Mac OS X comes with its own implementation of OpenSSH, so you don't need to install any third-party software to take advantage of the extra security SSH offers. Just open a terminal window and jump in.</p>"},{"location":"docs/about/login/#learning-more-about-ssh","title":"Learning more about SSH","text":"<p>To learn more about using SSH, please also consult the OpenSSH page page and take a look at the manual page on your system (man ssh).</p>"},{"location":"docs/about/login/#logging-in-to-the-compute-nodes","title":"Logging in to the compute nodes","text":"<p>Some times you may want to log in to a compute node (for instance to check out output files on the local scratch space on the compute node). This is also done by using SSH. On the login node do:</p> <pre><code>ssh compute-node     (for instance: ssh compute-0-1)\n</code></pre> <p>Please note you must have a running job on this compte node, otherwise SLURM will not allow you to log in to this compute node.</p>"},{"location":"docs/about/login/#x-forwarding-for-graphical-softwares","title":"X-forwarding for graphical softwares","text":"<p>If you need X-forwarding (for instance, if you like to run Mathematica in it's own window) you must log in like this:</p> <pre><code>ssh -Y username@login-node\n</code></pre> <p>Then you must submit an x11-enabled-interactive-job to get a terminal (this will give you access to the compute nodes such as <code>compute-0-0</code>). You should be able to run your program in this terminal and after a few seconds (depending to your network connection) the program window should be appeared. To test it you can test xclock. In this terminal type</p> <pre><code>xclock\n</code></pre> <p>If a small clock appears on your local screen, everything is OK.</p>"},{"location":"docs/acknowledgment/acknowledgment/","title":"How to acknowledge Scicluster","text":"<p>If you benefit Scilcuster in your works, please acknowledge it with this wording:</p> <p>The calculation was performed at the Sci-HPC center of the Ferdowsi University of Mashhad.</p> <p>This will help us demonstrate the impact of this resource on the research at FUM or other centers. Thanks </p>"},{"location":"docs/development/building/","title":"Building softwares","text":"<p>How to get software you need up and running on Scicluster?</p> <p>We recommend either use existing software modules, Anaconda, or pre-compiled software where available. However, there are cases where compiling applications is necessary or desired. This can be because the pre-compiled version isn't readily available/compatible or because compiling applications on the cluster will make an appreciable difference in performance. It is also the case that many R packages are compiled at install time.</p> <p>When building softwares on the clusters, it is critical to consider the ways in which you expect to run the software you are attempting to get working. If you want to be able to run jobs calling your application any node on the cluster, you will need to target the oldest hardware available so that newer optimizations are not used that will fail on some nodes. If your application is already quite specialized (e.g. needs GPUs or brand-new CPU instructions), you will want to compile it natively for the subset of compute nodes on which your jobs will run. This decision is often a trade-off between faster individual jobs or jobs that can run on more nodes at once.</p>"},{"location":"docs/development/building/#local-installation","title":"Local installation","text":"<p>Because you don't have admin/root/sudo privileges on Scicluster (and any other shared clusters), you will not be able to use sudo and a package manager like apt, yum, etc.; You will need to adapt install instructions to allow for what is called a local or user install.</p> <p>For things to work smoothly you will need to choose and stick with a prefix, or path to your installed applications and libraries. We recommend this be either in your home or project directory (more recommended actually, see quota), something like <code>~/software</code> or <code>/work8/$USER/software</code>. Make sure you have created it before continuing.</p> <p>Once you've chosen a prefix you will want to add any directory with executables you want to run to your <code>PATH</code> environment variable, and any directories with libraries that your application(s) link to your <code>LD_LIBRARY_PATH</code> environment variable. Each of these tell your shell where to look when you call your application without specifying an absolute path to it. To set these variables permanently, add the following to the end of your <code>~/.bashrc</code> file:</p> <pre><code>export MY_PREFIX=~/software\nexport PATH=$MY_PREFIX/bin:$PATH\nexport LD_LIBRARY_PATH=$MY_PREFIX/lib:$LD_LIBRARY_PATH\n</code></pre> <p>For the remainder of the guide we'll use the <code>$MY_PREFIX</code> variable to refer to the prefix. See below or your application's install instructions for exactly how to specify your prefix at build/install time.</p>"},{"location":"docs/development/building/#dependencies","title":"Dependencies","text":"<p>You will need to develop a build strategy that works for you and stay consistent. If you're happy using libraries and toolchains that are already available on the cluster as dependencies (recommended), feel free to create module collections that serve as your environments. If you prefer to completely build your own software tree, that is ok too. Whichever route you choose, try to stick with the same version of dependencies (e.g. MPI, zlib, numpy) and compiler you're using (e.g. GCC, intel). We find that unless absolutely necessary, the newest version of a compiler or library might not be the most compatible with a wide array of scientific software so you may want to step back a few versions or try using what was available at the time your application was being developed.</p>"},{"location":"docs/development/building/#autotools-configuremake","title":"Autotools (configure/make)","text":"<p>If your application includes instructions to run ./bootstrap, ./autogen.sh, ./configure or make, it is using the GNU Build System.</p>"},{"location":"docs/development/building/#configure","title":"<code>configure</code>","text":"<p>If you are instructed to run <code>./configure</code> to generate a Makefile, specify your prefix with the <code>--prefix</code> option. This creates a file, usually named <code>Makefile</code> that is a recipe for make to use to build your application.</p> <pre><code>export MY_PREFIX=~/software\n./configure --prefix=$MY_PREFIX\n</code></pre>"},{"location":"docs/development/building/#make-install","title":"<code>make install</code>","text":"<p>If your configure ran properly, <code>make</code> will compile your code and <code>make install</code> should properly place your application in your prefix directory. If there is no install target specified for your application, you can either run make and copy the application to your <code>$MY_PREFIX/bin</code> directory or build it somewhere in <code>$MY_PREFIX</code> and add its relevant paths to your <code>PATH</code> and/or <code>LD_LIBRARY_PATH</code> environment variables in your <code>~/.bashrc</code> file as shown in the local install section.</p>"},{"location":"docs/development/building/#cmake","title":"CMake","text":"<p>CMake is a popular cross-platform build system. On a Gnu/Linux system, CMake will create a <code>Makefile</code> in a step analogous to <code>./configure</code>.  It is common to create a build directory then run the <code>cmake</code> and <code>make</code> commands from there. Below is what installing to your <code>$MY_DIRECTORY</code> prefix might look like with CMake.</p> <pre><code>export MY_PREFIX=~/software\nmkdir build \ncd build \ncmake -DCMAKE_INSTALL_PREFIX=$MY_PREFIX \nmake\nmake install\n</code></pre>"},{"location":"docs/development/compilers/","title":"Compilers","text":"<p>The default development environment on Scicluster is provided by GNU Compiler Collection. The GNU foundation maintains a number of high quality compilers, including a compiler for C (gcc), C++ (g++), and Fortran (gfortran). The gcc compiler is the foundation underneath all three, and the term \"gcc\" often means the suite of these three GNU compilers.</p>"},{"location":"docs/development/compilers/#version","title":"Version","text":"<p>Currently we provide  <code>GCC-7.3</code>, <code>GCC-9.3</code>, <code>GCC-10.2</code>, <code>GCC-10.3</code>, <code>GCC/11.2.0</code> and <code>GCC/12.3.0</code> at the moment, via module system. To enable 7.3 version as e.g., run</p> <pre><code>ml GCCcore/7.3.0\n</code></pre> <p>To disable,</p> <pre><code>ml unload GCCcore/7.3.0.\n</code></pre> <p>and to see all,</p> <pre><code>ml spider GCC\n</code></pre>"},{"location":"docs/development/compilers/#fortran-compilers","title":"Fortran compilers","text":"<p>GNU fortran compiler can be invoked by: <code>gfortran</code>.</p>"},{"location":"docs/development/compilers/#usage-of-gnu-fortran-compiler","title":"Usage of GNU fortran compiler","text":"<p>For plain Fortran codes (all Fortran standards) the general form for usage of the gnu fortran compiler is as follows:</p> <pre><code>gfortran [options] file1 [file2 ...]\n</code></pre> <p>where options represents zero or more compiler options, and fileN is a Fortran source (.f .for .ftn .f90 .fpp .F .FOR .F90), assembly (.s .S), object (.o), static library (.a), or an other linkable file.</p> <p>The form above also applies for Fortran codes parallelized with OpenMP, in Wikipedia; you only have to select the necessary compiler options for OpenMP.</p> <p>For Fortran codes parallelized with MPI the general form is quite similar:</p> <pre><code>mpif90 [options] file1 [file2 ...]\n</code></pre> <p>The wrapper mpif90 is using the gfortran compiler and invokes all the necessary MPI machinery automatically for you.  Therefore, everything else is the same for compiling MPI codes as for compiling plain Fortran codes.</p>"},{"location":"docs/development/compilers/#c-and-c-compilers","title":"C and C++ compilers","text":"<p>GNU C/C++ compiler can be invoked by: <code>gcc</code> and <code>g++</code> correspondingly.</p>"},{"location":"docs/development/compilers/#usage-of-gnu-cc-compilers","title":"Usage of GNU C/C++ compilers","text":"<p>For plain C/C++ codes the general form for usage of the GNU gcc/g++ compilers are as follows:</p> <pre><code>gcc  [options] file1 [file2 ...]  # C\ng++ [options] file1 [file2 ...]  # C++\n</code></pre> <p>where options represents zero or more compiler options, fileN is a C/C++ source (.C .c .cc .cpp .cxx .c++), assembly (.s .S), object (.o), static library (.a), or other linkable file.</p> <p>The form above also applies for C/C++ codes parallelized with OpenMP; you only have to select the necessary compiler options for OpenMP.</p> <p>For C/C++ codes parallelized with MPI the general form is quite similar:</p> <pre><code>mpicc [options] file1 [file2 ...]  # C when using OpenMPI\nmpic++ [options] file1 [file2 ...]  # C++ when using OpenMPI\n</code></pre> <p>Both mpicc and mpic++ are using the GNU compilers, they are just wrappers that invoke all the necessary MPI machinery automatically for you. Therefore, everything else is the same for compiling MPI codes as for compiling plain C/C++ codes.</p>"},{"location":"docs/development/environment/","title":"Environment modules","text":"<p>The user's environment, and which programs are available for immediate use, is controlled by the <code>module</code> command. Many development libraries are dependant on a particular compiler versions, and at times a specific MPI library. When loading and/or unloading a compiler, <code>module</code> automatically unloads incompatible modules and, if possible, reloads compatible versions.</p> <p>Currently, not all libraries in all combinations of all compilers and MPI implementations are supported. By using the default compiler and MPI library, these problems can be avoided. In the future, we aim to automate the process so that all possible (valid) permutations are allowed.</p> <p>Read the Module section for an introduction on how to use modules.</p>"},{"location":"docs/development/toolchains_easybuild/","title":"Toolchains and EasyBuild","text":"<p>We use a build and installation framework called EasyBuild that provides module files for the software we build.</p>"},{"location":"docs/development/toolchains_easybuild/#toolchains","title":"Toolchains","text":"<p>When we install applications, we use pre-defined build environments called toolchains. These are modules that include core compilers and libraries (e.g. GCC, OpenMPI, zlib). We do this to keep our build process simpler and also provide the same software built with different compilers and options. The two common toolchains you will interact with are <code>foss</code> and <code>intel</code> (currently we don't have <code>intel</code> in our cluster). Each of these have module versions corresponding to the year they were built. Toolchain name and version information is appended to the name of a module so it is clear what will be compatible. For example GSL/2.3-foss-2018b, the software name is GSL (version 2.3) that is built with the foss toolchain version 2018b. The easiest way to see what software a toolchain includes is to load it and then list loaded modules.</p> <pre><code>ml foss/2018b\n</code></pre> <p>then</p> <pre><code>ml list\n</code></pre> <p>which shows the loaded modules</p> <pre><code>Currently Loaded Modules:\n1) GCCcore/7.3.0                  6) XZ/5.2.4-GCCcore-7.3.0           11) OpenBLAS/0.3.1-GCC-7.3.0-2.30\n2) zlib/1.2.11-GCCcore-7.3.0      7) libxml2/2.9.8-GCCcore-7.3.0      12) gompi/2018b\n3) binutils/2.30-GCCcore-7.3.0    8) libpciaccess/0.14-GCCcore-7.3.0  13) FFTW/3.3.8-gompi-2018b\n4) GCC/7.3.0-2.30                 9) hwloc/1.11.10-GCCcore-7.3.0      14) ScaLAPACK/2.0.2-gompi-2018b-OpenBLAS-0.3.1\n5) numactl/2.0.11-GCCcore-7.3.0  10) OpenMPI/3.1.1-GCC-7.3.0-2.30     15) foss/2018b\n</code></pre>"},{"location":"docs/development/toolchains_easybuild/#toolchain-trees","title":"Toolchain Trees","text":"<p>One place toolchains can be a little confusing is that there are various levels to a given toolchain depending on how many libraries are included. For example, <code>foss/2018b</code> is a parent toolchain to <code>GCCcore/7.3.0</code> since <code>foss</code> includes <code>GCC-7.3.0</code> as well as <code>OpenMPI-3.1.1</code>. The following toolchains could be considered as a tree (leaf to root):</p>"},{"location":"docs/development/toolchains_easybuild/#base-toolchains","title":"Base toolchains","text":"<p><code>GCCcore</code> - GCC compiler</p>"},{"location":"docs/development/toolchains_easybuild/#toolchains-with-mpi","title":"Toolchains with MPI","text":"<p><code>gompi</code> - GCCcore + OpenMPI</p>"},{"location":"docs/development/toolchains_easybuild/#full-toolchains-also-include-math-libraries","title":"Full toolchains (also include math libraries)","text":"<p><code>foss</code> - gompi + OpenBLAS + ScalaPack</p>"},{"location":"docs/jobs/batch/","title":"Batch","text":"<p>.. _batch_system:</p>"},{"location":"docs/jobs/batch/#batch-system","title":"Batch system","text":"<p>The Scicluster system is a resource that is shared between many of users and to ensure fair use everyone must do their computations by submitting jobs through a batch system that will execute the applications on the available resources.</p> <p>The batch system on Scicluster is <code>SLURM &lt;https://slurm.schedmd.com/&gt;</code>_ (Simple Linux Utility for Resource Management.)</p>"},{"location":"docs/jobs/batch/#creating-a-job-script","title":"Creating a job script","text":"<p>To run a job on the system you need to create a job script. A job script is a regular shell script (bash) with some directives started by <code>#SBATCH</code> specifying the number of CPUs, memory, etc., that will be interpreted by the batch system upon submission.</p> <p>You can find job script examples in :ref:<code>job_script_examples</code>.</p> <p>After you wrote your job script as shown in the examples, you can start it with::</p> <p>sbatch jobscript.sh</p>"},{"location":"docs/jobs/batch/#how-to-pass-command-line-parameters-to-the-job-script","title":"How to pass command-line parameters to the job script","text":"<p>It is sometimes convenient if you do not have to edit the job script every time you want to change the input file. Or perhaps you want to submit hundreds of jobs and loop over a range of input files. For this it is handy to pass command-line parameters to the job script. For an overview of the different possible parameters, see :ref:<code>slurmparameter</code>.</p> <p>In SLURM you can do this::</p> <p>$ sbatch myscript.sh myinput myoutput</p> <p>And then you can pick the parameters up inside the job script using <code>${n}</code> where <code>n</code> is the nth parameter::</p> <p>#!/bin/bash</p> <p>#SBATCH ...   #SBATCH ...   ...</p> <p># argument 1 is myinput   # argument 2 is myoutput   mybinary.x &lt; ${1} &gt; ${2}</p>"},{"location":"docs/jobs/batch/#priority","title":"Priority","text":"<p>We recommend you to be as precise as you can when specifying the parameters as they will inflict on how fast your jobs will start to run. We generally use fairshare for prioritizing jobs. This means that users with many jobs running will get a decreased priority compared to other users.</p> <p>.. #. Large jobs, that is jobs with high CPUcounts, are prioritized. .. #. Short jobs take precedence over long jobs.</p> <p>To display information for all users, run::</p> <p>$ sshare -a</p>"},{"location":"docs/jobs/dos_and_donts/","title":"Dos and don'ts","text":"<ul> <li>Never run calculations on the home disk, instead use <code>work</code> space.</li> <li>Always use the SLURM queueing system</li> <li>The frontend/login node is only for editing files, compiling, downloading required files and submitting jobs.</li> </ul>"},{"location":"docs/jobs/examples/","title":"Job script examples","text":""},{"location":"docs/jobs/examples/#general-blueprint-for-a-jobscript","title":"General blueprint for a jobscript","text":"<p>You can save the following example to a file (e.g. run.sh) on scicluster. Comment the two <code>cp</code> commands that are just for illustratory purpose (lines 46 and 55) and change the SBATCH directives where applicable. You can then run the script by typing:</p> <pre><code>sbatch run.sh\n</code></pre> <p>Please note that all values that you define with SBATCH directives are hard values. When you, for example, ask for 6000 MB of memory (<code>--mem=6000MB</code>) and your job uses more than that, the job will be automatically killed by the manager.</p> <p>Important: Please note that the standard out and err streams from the code are redirected to a file despite the specification of standard out and err for the job. This is very important unless stdout/stderr from your code is less than a few MB. The job output is spooled locally on the execution node and copied to the user working directory only after the job completes. Since the spool size is small (a few GB) you can overfill the disk and crash all the jobs on the node. With redirection approach you avoid this and in addition you can monitor out.txt during runtime.</p> <pre><code>#!/bin/bash -l\n\n##############################\n#       Job blueprint        #\n##############################\n\n# Give your job a name, so you can recognize it in the queue overview\n#SBATCH --job-name=example\n\n# Define, how many nodes you need. Here, we ask for 1 node.\n#SBATCH --nodes=1\n# You can further define the number of tasks with --ntasks-per-*\n# See \"man sbatch\" for details. e.g. --ntasks=4 will ask for 4 cpus.\n\n# Define, how long the job will run in real time. This is a hard cap meaning\n# that if the job runs longer than what is written here, it will be\n# force-stopped by the server. If you make the expected time too long, it will\n# take longer for the job to start. Here, we say the job will take 5 minutes.\n#              d-hh:mm:ss\n#SBATCH --time=0-00:05:00\n\n# Define the partition on which the job shall run, e.g. long\n#SBATCH --partition long\n\n# How much memory you need.\n# --mem will define memory per node and\n# --mem-per-cpu will define memory per CPU/core. Choose one of those.\n#SBATCH --mem-per-cpu=1500MB\n##SBATCH --mem=5GB    # this one is not in effect, due to the double hash\n\n#SBATCH --output=\"stdout.txt\" # standard output\n#SBATCH --error=\"stderr.txt\"  # standard error &lt;-- This is our last SBATCH directive\n\n# You may not place any commands before the last SBATCH directive\n\n# Define and create a unique scratch directory for this job\nSCRATCH_DIRECTORY=/scratch1/${USER}/${SLURM_JOBID}\nmkdir -p ${SCRATCH_DIRECTORY}\ncd ${SCRATCH_DIRECTORY}\n\n# You can copy everything you need to the scratch directory\n# ${SLURM_SUBMIT_DIR} points to the path where this script was submitted from\ncp ${SLURM_SUBMIT_DIR}/myfile.txt ${SCRATCH_DIRECTORY}\n\nml purge # it's a good practice to first unload all modules\nml your_modules # then load what module you need, if any\n\n# This is where the actual work is done.\n./my_code &gt;&amp; out.txt\n\n# After the job is done we copy our output back to $SLURM_SUBMIT_DIR\ncp ${SCRATCH_DIRECTORY}/my_output ${SLURM_SUBMIT_DIR}\n\n\n# After everything is saved to your home directory, it's recommended to delete the work directory to\n# save space on /scratch1\ncd ${SLURM_SUBMIT_DIR}\nrm -rf ${SCRATCH_DIRECTORY}\n\n# Finish the script\nexit 0\n</code></pre>"},{"location":"docs/jobs/examples/#job-arrays","title":"Job arrays","text":""},{"location":"docs/jobs/examples/#running-many-sequential-jobs-in-parallel-using-job-arrays","title":"Running many sequential jobs in parallel using job arrays","text":"<p>In this example we wish to run many similar sequential jobs in parallel using job arrays. We take Python as an example but this does not matter for the job arrays:</p> <pre><code>#!/usr/bin/env python\n\nimport time\n\nprint('start at ' + time.strftime('%H:%M:%S'))\n\nprint('sleep for 10 seconds ...')\ntime.sleep(10)\n\nprint('stop at ' + time.strftime('%H:%M:%S'))\n</code></pre> <p>Save this to a file called \"test.py\" and try it out: <code>python test.py</code></p> <pre><code>start at 15:23:48\nsleep for 10 seconds ...\nstop at 15:23:58\n</code></pre> <p>Good. Now we would like to run this script 8 times at the same time. For this we use the following script:</p> <pre><code>#!/bin/bash -l\n\n#####################\n# job-array example #\n#####################\n\n#SBATCH --job-name=example\n\n# 8 jobs will run in this array at the same time\n#SBATCH --array=1-8\n\n# run for five minutes\n#              d-hh:mm:ss\n#SBATCH --time=0-00:05:00\n\n# determine the partition\n#SBATCH --partition=short\n\n# 100MB memory per core\n#SBATCH --mem-per-cpu=100MB\n\n#SBATCH --output=\"stdout.txt\"\n#SBATCH --error=\"stderr.txt\"\n\n# you may not place bash commands before the last SBATCH directive\n\nml purge # it's a good practice to first unload all modules\nml your_modules # then load what module you need, if any\n\n# define and create a unique scratch directory\nSCRATCH_DIRECTORY=/scratch1/${USER}/job-array-example/${SLURM_JOBID}\nmkdir -p ${SCRATCH_DIRECTORY}\ncd ${SCRATCH_DIRECTORY}\n\ncp ${SLURM_SUBMIT_DIR}/test.py ${SCRATCH_DIRECTORY}\n\n# each job will see a different ${SLURM_ARRAY_TASK_ID}\necho \"now processing task id:: \" ${SLURM_ARRAY_TASK_ID}\n\nml purge # unload all modules\nml Anaconda3 # load Anaconda3 module to use python\n\npython test.py &gt; output_${SLURM_ARRAY_TASK_ID}.txt\n\n# after the job is done we copy our output back to $SLURM_SUBMIT_DIR\ncp output_${SLURM_ARRAY_TASK_ID}.txt ${SLURM_SUBMIT_DIR}\n\n# we step out of the scratch directory and remove it\ncd ${SLURM_SUBMIT_DIR}\nrm -rf ${SCRATCH_DIRECTORY}\n\n# happy end\nexit 0\n</code></pre> <p>Submit the script and after a short while you should see 8 output files in your submit directory:</p> <pre><code>ls -l output*.txt\n\n-rw------- 1 user user 60 Oct 14 14:44 output_1.txt\n-rw------- 1 user user 60 Oct 14 14:44 output_10.txt\n-rw------- 1 user user 60 Oct 14 14:44 output_11.txt\n-rw------- 1 user user 60 Oct 14 14:44 output_12.txt\n-rw------- 1 user user 60 Oct 14 14:44 output_13.txt\n-rw------- 1 user user 60 Oct 14 14:44 output_14.txt\n-rw------- 1 user user 60 Oct 14 14:44 output_15.txt\n-rw------- 1 user user 60 Oct 14 14:44 output_16.txt\n</code></pre>"},{"location":"docs/jobs/examples/#packaging-smaller-parallel-jobs-into-one-large-parallel-job","title":"Packaging smaller parallel jobs into one large parallel job","text":"<p>There are several ways to package smaller parallel jobs into one large parallel job. The preferred way is to use Job Arrays. Browse the web for many examples on how to do it. Here we want to present a more pedestrian alternative which can give a lot of flexibility.</p> <p>In this example we imagine that we wish to run 2 MPI jobs at the same time, each using 4 tasks, thus totalling to 8 tasks.  Once they finish, we wish to do a post-processing step and then resubmit another set of 2 jobs with 4 tasks each:</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=example\n#SBATCH --ntasks=8\n#SBATCH --time=0-00:05:00\n#SBATCH --mem-per-cpu=100MB\n#SBATCH --output=\"stdout.txt\"\n#SBATCH --error=\"stderr.txt\"\n\n# determine the partition\n#SBATCH --partition=para\n\ncd ${SLURM_SUBMIT_DIR}\n\n# first set of parallel runs\n\nml purge\nml OpenMPI\n\nmpirun -n 4 ./my-binary &amp;\nmpirun -n 4 ./my-binary &amp;\n\nwait\n\n# here a post-processing step\n# ...\n\n# another set of parallel runs\nmpirun -n 4 ./my-binary &amp;\nmpirun -n 4 ./my-binary &amp;\n\nwait\n\nexit 0\n</code></pre> <p>The <code>wait</code> commands are important here - the run script will only continue once all commands started with <code>&amp;</code> have completed.</p>"},{"location":"docs/jobs/examples/#openmp-and-mpi","title":"OpenMP and MPI","text":"<p>You can copy and paste the examples given here to a file (e.g. run.sh) and start it with:</p> <pre><code>sbatch run.sh\n</code></pre>"},{"location":"docs/jobs/examples/#example-for-an-openmp-job","title":"Example for an OpenMP job","text":"<pre><code>#!/bin/bash -l\n\n#############################\n# example for an OpenMP job #\n#############################\n\n#SBATCH --job-name=example\n\n# we ask for 1 task with 12 cores\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=12\n\n# ask for 16GB memory\n#SBATCH --mem=16G\n\n# run for five minutes\n#              d-hh:mm:ss\n#SBATCH --time=0-00:05:00\n\n# determine the partition\n#SBATCH --partition=para\n\n#SBATCH --output=\"stdout_%j\"\n#SBATCH --error=\"stderr_%j\"\n\n# you may not place bash commands before the last SBATCH directive\n\nml purge # it's a good practice to first unload all modules\nml your_modules # then load what module you need, if any\n\n# define and create a unique scratch directory\nSCRATCH_DIRECTORY=/scratch1/${USER}/example/${SLURM_JOBID}\nmkdir -p ${SCRATCH_DIRECTORY}\ncd ${SCRATCH_DIRECTORY}\n\n# we copy everything we need to the scratch directory\n# ${SLURM_SUBMIT_DIR} points to the path where this script was submitted from\ncp ${SLURM_SUBMIT_DIR}/my_binary.x ${SCRATCH_DIRECTORY}\n\n# we set OMP_NUM_THREADS to the number of available cores\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}\n\n# we execute the job and time it\ntime ./my_binary.x &gt; my_output\n\n# after the job is done we copy our output back to $SLURM_SUBMIT_DIR\ncp ${SCRATCH_DIRECTORY}/my_output ${SLURM_SUBMIT_DIR}\n\n# we step out of the scratch directory and remove it\ncd ${SLURM_SUBMIT_DIR}\nrm -rf ${SCRATCH_DIRECTORY}\n</code></pre>"},{"location":"docs/jobs/examples/#example-for-an-mpi-job","title":"Example for an MPI job","text":"<pre><code>#!/bin/bash -l\n\n##########################\n# example for an MPI job #\n##########################\n\n#SBATCH --job-name=example\n\n# 20 MPI tasks in total\n#SBATCH --ntasks=20\n\n# run for five minutes\n#              d-hh:mm:ss\n#SBATCH --time=0-00:05:00\n\n# 500MB memory per core\n#SBATCH --mem-per-cpu=500MB\n\n# determine the partition\n#SBATCH --partition=para\n\n#SBATCH --output=\"stdout_%j\"\n#SBATCH --error=\"stderr_%j\"\n\n# you may not place bash commands before the last SBATCH directive\n\n# define and create a unique shared directory\nSHARED_DIRECTORY=/work8/${USER}/${SLURM_JOBID} # please note it's vital to use /work8 for shared drectory\nmkdir -p ${SHARED_DIRECTORY}\ncd ${SHARED_DIRECTORY}\n\n# unload all modules then load your OMP modules\nml purge\nml OpenMPI\n\n# we execute the job and time it\ntime mpirun -np $SLURM_NTASKS ./my_binary.x &amp;&gt; my_output\n\n# happy end\nexit 0\n</code></pre>"},{"location":"docs/jobs/examples/#example-for-a-hybrid-mpiopenmp-job","title":"Example for a hybrid MPI/OpenMP job","text":"<pre><code>#!/bin/bash -l\n\n#######################################\n# example for a hybrid MPI OpenMP job #\n#######################################\n\n#SBATCH --job-name=example\n\n# we ask for 2 MPI tasks with 18 cores each on 1 node\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=2\n#SBATCH --cpus-per-task=18\n\n# run for five minutes\n#              d-hh:mm:ss\n#SBATCH --time=0-00:05:00\n\n# 500MB memory per core\n#SBATCH --mem-per-cpu=500MB\n\n# determine the partition\n#SBATCH --partition=para\n\n#SBATCH --output=\"stdout_%j\"\n#SBATCH --error=\"stderr_%j\"\n\n# you may not place bash commands before the last SBATCH directive\n\n# define and create a unique shared directory\nSHARED_DIRECTORY=/work8/${USER}/${SLURM_JOBID} # please note it's vital to use /work8 for shared drectory\nmkdir -p ${SHARED_DIRECTORY}\ncd ${SHARED_DIRECTORY}\n\n# unload all modules then load your OMP modules\nml purge\nml OpenMPI\n\n# we set OMP_NUM_THREADS to the number cpu cores per MPI task\nexport OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}\n\n# we execute the job and time it\ntime mpirun -np $SLURM_NTASKS ./my_binary.x &amp;&gt; my_output\n\n# happy end\nexit 0\n</code></pre> <p>If you want to start more than one MPI rank per node you can use <code>--ntasks-per-node</code> in combination with <code>--nodes</code>:</p> <pre><code>#SBATCH --nodes=2 --ntasks-per-node=2 --cpus-per-task=8\n</code></pre> <p>This will start 2 MPI tasks each on 2 nodes, where each task can use up to 8 threads.</p>"},{"location":"docs/jobs/examples/#example-for-a-gpu-job","title":"Example for a GPU job","text":"run-p4000.shrun-k80.shstats.cu <pre><code>#!/bin/bash -l\n#############################\n# example for a GPU job #\n#############################\n\n#SBATCH --job-name=example\n\n# we can ask for 1 p4000, 1 k80 or 2 k80 gpus.\n#SBATCH --gpus=p4000\n\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=20\n#SBATCH --mem=32G\n#SBATCH --time=0-00:05:00\n#SBATCH --partition=para\n\n#SBATCH --output=\"p4000.out\"\n#SBATCH --error=\"p4000.err\"\n\n# you may not place bash commands before the last SBATCH directive\n\nml purge # it's a good practice to first unload all modules\nml CUDA  # then load what module you need\n\n##Compile the cuda code using the nvcc compiler\nnvcc -o stats.exe stats.cu\n\n## Run the code\n./stats.exe\nrm ./stats.exe\n</code></pre> <pre><code>#!/bin/bash -l\n#############################\n# example for a GPU job #\n#############################\n\n#SBATCH --job-name=example\n\n# we can ask for 1 p4000, 1 k80 or 2 k80 gpus.\n#SBATCH --gpus=k80:2\n\n#SBATCH --ntasks-per-node=1\n#SBATCH --cpus-per-task=36\n#SBATCH --mem=32G\n#SBATCH --time=0-00:05:00\n#SBATCH --partition=para\n\n#SBATCH --output=\"k80.out\"\n#SBATCH --error=\"k80.err\"\n\n# you may not place bash commands before the last SBATCH directive\n\nml purge # it's a good practice to first unload all modules\nml CUDA  # then load what module you need\n\n##Compile the cuda code using the nvcc compiler\nnvcc -o stats.exe stats.cu\n\n## Run the code\n./stats.exe\nrm ./stats.exe\n</code></pre> <pre><code>#include &lt;stdio.h&gt;\n#include &lt;cuda_runtime.h&gt;\n\nvoid printDeviceInfo(cudaDeviceProp prop) {\n\n   printf(\"Name                         - %s\\n\",  prop.name);\n   printf(\"Total global memory          - %lu MB \\n\", prop.totalGlobalMem/(1024*1024));\n   printf(\"Total constant memory        - %lu KB \\n\", prop.totalConstMem/1024);\n\n   printf(\"Shared memory per block      - %lu KB \\n\", prop.sharedMemPerBlock/1024);\n   printf(\"Total registers per block    - %d\\n\", prop.regsPerBlock);\n   printf(\"Maximum threads per block    - %d\\n\", prop.maxThreadsPerBlock);\n\n   printf(\"Clock rate                   - %d\\n\",  prop.clockRate);\n   printf(\"Number of multi-processors   - %d\\n\",  prop.multiProcessorCount);\n\n  }\n\nint main( ) {\n\n    int deviceCount;\n    cudaGetDeviceCount(&amp;deviceCount);\n    printf(\"Available CUDA devices - %d\\n\", deviceCount);\n    for (int i=0;i&lt;deviceCount;i++){\n\n        // Device informatioon\n        printf(\"\\nCUDA Device #%d\\n\", i);\n        cudaDeviceProp prop;\n        cudaGetDeviceProperties(&amp;prop, i);\n        printDeviceInfo(prop);\n\n    }\n}\n</code></pre>"},{"location":"docs/jobs/examples/#general-tips","title":"General tips","text":""},{"location":"docs/jobs/examples/#example-on-how-to-allocate-entire-memory-on-one-node","title":"Example on how to allocate entire memory on one node","text":"<pre><code>#!/bin/bash -l\n\n###################################################\n# Example for a job that consumes a lot of memory #\n###################################################\n\n#SBATCH --job-name=example\n\n# we ask for 1 node\n#SBATCH --nodes=1\n\n# run for five minutes\n#              d-hh:mm:ss\n#SBATCH --time=0-00:05:00\n\n# determine the partition, e.g. long\n#SBATCH --partition=long \n\n# total memory for this job\n# this is a hard limit\n# note that if you ask for more than one CPU has, your account gets\n# charged for the other (idle) CPUs as well\n#SBATCH --mem=16000MB\n\n#SBATCH --output=\"stdout.txt\"\n#SBATCH --error=\"stderr.txt\"\n\n# you may not place bash commands before the last SBATCH directive\n\nml purge # it's a good practice to first unload all modules\nml your_modules # then load what module you need, if any\n\nSCRATCH_DIRECTORY=/scratch1/${USER}/example/${SLURM_JOBID}\nmkdir -p ${SCRATCH_DIRECTORY}\ncd ${SCRATCH_DIRECTORY}\n\n# we copy everything we need to the scratch directory\n# ${SLURM_SUBMIT_DIR} points to the path where this script was submitted from\ncp ${SLURM_SUBMIT_DIR}/my_binary.x ${SCRATCH_DIRECTORY}\n\n# we execute the job and time it\ntime ./my_binary.x &gt; my_output\n\n# after the job is done we copy our output back to $SLURM_SUBMIT_DIR\ncp ${SCRATCH_DIRECTORY}/my_output ${SLURM_SUBMIT_DIR}\n\n# we step out of the scratch directory and remove it\ncd ${SLURM_SUBMIT_DIR}\nrm -rf ${SCRATCH_DIRECTORY}\n\n# happy end\nexit 0\n</code></pre>"},{"location":"docs/jobs/examples/#how-to-recover-files-before-a-job-times-out","title":"How to recover files before a job times out","text":"<p>Possibly you would like to clean up the work directory or recover files for restart in case a job times out. In this example we ask Slurm to send a signal to our script 120 seconds before it times out to give us a chance to perform clean-up actions.</p> <pre><code>#!/bin/bash -l\n\n# job name\n#SBATCH --job-name=example\n\n# one core only\n#SBATCH --ntasks=1\n\n# we give this job 4 minutes\n#SBATCH --time=0-00:04:00\n\n# asks SLURM to send the USR1 signal 120 seconds before end of the time limit\n#SBATCH --signal=B:USR1@120\n\n# define the handler function\n# note that this is not executed here, but rather\n# when the associated signal is sent\nyour_cleanup_function()\n{\n    echo \"function your_cleanup_function called at $(date)\"\n    # do whatever cleanup you want here\n}\n\n# call your_cleanup_function once we receive USR1 signal\ntrap 'your_cleanup_function' USR1\n\necho \"starting calculation at $(date)\"\n\n# the calculation \"computes\" (in this case sleeps) for 1000 seconds\n# but we asked slurm only for 240 seconds so it will not finish\n# the \"&amp;\" after the compute step and \"wait\" are important\nsleep 1000 &amp;\nwait\n</code></pre>"},{"location":"docs/jobs/interactive/","title":"Interactive job","text":""},{"location":"docs/jobs/interactive/#starting-an-interacitve-job","title":"Starting an interacitve job","text":"<p>You can run an interactive job like this:</p> <pre><code>srun -p short --nodes=1 --ntasks-per-node=1 --time=01:00:00 --pty bash -i\n</code></pre> <p>Here we ask for a single core on one interactive node for one hour with the default amount of memory in the short partition. The command prompt will appear as soon as the job starts. You can add other options same as when you prepare a bath script like <code>--mem</code>, <code>-p</code>, <code>-w</code> and etc.</p> <p>Exit the bash shell to end the job. If you exceed the time or memory limits the job will also abort.</p> <p>Interactive jobs have the same policies as normal batch jobs, there are no extra restrictions. You should be aware that you might be sharing the node with other users, so play nice.</p>"},{"location":"docs/jobs/interactive/#keeping-interactive-jobs-alive","title":"Keeping interactive jobs alive","text":"<p>Interactive jobs die when you disconnect from the frontend node either by choice or by internet connection problems.</p> <p>To ease running an interacitve job, we define a command wich you can find its help as <code>interacitve -h</code>. As an example do:</p> <pre><code>interactive -c1 -w compute-0-0 -p short\n</code></pre>"},{"location":"docs/jobs/interactive/#x11-enabled-interactive-job","title":"X11 enabled interactive job","text":"<p>As our current slurm <code>srun</code> command does not forward X11 automatically, you can use <code>srun.x11</code> command for those interactive jobs which need to forward X11. For example:</p> <pre><code>srun.x11 -p short --nodes=1 --ntasks-per-node=1 --time=01:00:00 --mem=4GB\n</code></pre> <p>To test run the simple <code>xclock</code> program in the terminal session provided to you.</p> <p>Like the <code>sun</code> command, you can use slurm option according to your needs. Please note for proper forwarding of X11 to your local computer, you had to log in to the login node with <code>-Y -X</code> arguments. See login for more info.</p>"},{"location":"docs/jobs/job_management/","title":"Managing jobs","text":"<p>The lifecycle of a job can be managed with as little as three different commands:</p> <ul> <li>Submit the job with <code>sbatch &lt;script_name&gt;</code>.</li> <li>Check the job status with <code>squeue</code>. (to limit the display to only    your jobs use <code>squeue -u &lt;user_name&gt;</code>.)</li> <li>(optional) Delete the job with <code>scancel &lt;job_id&gt;</code>.</li> </ul> <p>You can also hold the start of a job: <code>scontrol hold &lt;job_id&gt;</code>, put a hold on the job. A job on hold will not start or block other jobs from starting until you release the hold. <code>scontrol release &lt;job_id&gt;</code>, release the hold on a job.</p>"},{"location":"docs/jobs/job_management/#job-status-descriptions-in-squeue","title":"Job status descriptions in squeue","text":"<p>When you run <code>squeue</code> (probably limiting the output with <code>squeue -u &lt;user_name&gt;</code>), you will get a list of all jobs currently running or waiting to start. Most of the columns should be self-explaining, but the ST and NODELIST (REASON) columns can be confusing.</p> <p>ST stands for state. The most important states are listed below. For a more comprehensive list, check the squeue help page section Job State Codes.</p> <ul> <li>R  The job is running</li> <li>PD  The job is pending (i.e. waiting to run)</li> <li>CG The job is completing, meaning that it will be finished soon</li> </ul> <p>The column NODELIST (REASON) will show you a list of computing nodes the job is running on if the job is actually running. If the job is pending, the column will give you a reason why it still pending. The most important reasons are listed below. For a more comprehensive list, check the squeue help page section Job Reason Codes.</p> <ul> <li>Priority   There is another pending job with higher priority</li> <li> <p>Resources   The job has the highest priority, but is waiting for some running job to finish.</p> </li> <li> <p>launch failed requeued held   Job launch failed for some reason. This is normally due to a faulty node. Please contact us, stating the problem, your user name, and the jobid(s).</p> </li> <li>Dependency   Job cannot start before some other job is finished. This should only happen if you started the job with <code>--dependency=...</code></li> <li>DependencyNeverSatisfied   Same as Dependency, but that other job failed. You must cancel the job with <code>scancel JOBID</code>.</li> </ul>"},{"location":"docs/jobs/monitoring/","title":"Monitoring your jobs","text":""},{"location":"docs/jobs/monitoring/#slurm-commands","title":"SLURM commands","text":"<p>To monitor your jobs, you can use of of those commands. For details run them with the <code>-</code>-help option:</p> <p><code>scontrol show jobid &lt;jobid&gt;</code> lists detailed information for a job (useful for troubleshooting). <code>scontrol show nodes</code> lists nodes and their properties.</p> <p><code>sacct -j &lt;jobid&gt; --format=JobID,JobName,MaxRSS,Elapsed</code> will give you statistics on completed jobs by jobID. Once your job has completed, you can get additional information that was not available during the run. This includes run time, memory used, etc.</p>"},{"location":"docs/jobs/monitoring/#cpu-load-and-memory-consumption-of-your-job","title":"CPU load and memory consumption of your job","text":"<p>Scicluster has only limited resources and usually a high demand. Therefore using the available resources as efficient as possible is paramount to have short queueing times and getting most out of your quota.</p>"},{"location":"docs/jobs/partition/","title":"Partitions (queues)","text":"<p>We use partitions in SLURM to manage resources in the cluster.</p> <p>We have the following partitions:</p> Partition MaxTime DefaultTime DefMemPerCPU Max number of  Nodes short 1 day 30 min 512 MB 1 long 1 week 30 min 512 MB 1 PARA 1 week 30 min 512 MB 4 <p>To display a straight-forward summary: available partitions, their job size, status, timelimit and node information with A/I/O/T (allocated, idle, other, and total):</p> <pre><code>sinfo -o \"%.10P %.15s %.10a %.10l %.15F\"\n</code></pre> <p>Numbers represent field length and should be used to properly accommodate the data.</p> <p>See About Scicluster chapter of the documentation if you need more information on the system architecture.</p>"},{"location":"docs/jobs/qos/","title":"Quality of servisec (QOS)","text":"<p>We have defined three QOSs (quality of service) for better management: low, normal and high.</p> QOS Max node per user Max wall time low 1 (this is the default QOS) 7 normal 2 1 high 3 1 <p>All members of the faculty of science have low, normal and high QOS which means they can use  1 node for 7 days or 2 or 3 nodes for 1 day. For example in your batch script you can write one of the below options:</p> <p><pre><code>## for 3 nodes\n#SBATCH --qos=high\n#SBATCH --ntasks=80\n#SBATCH -w compute-0-[0,2,3]\n#SBATCH --time=1-00:00:00 # maximum time for \"high\" QOS is 1 day\n</code></pre> <pre><code>## for 2 nodes (e.g. compute-0-0 and 0-3)\n#SBATCH --qos=normal\n#SBATCH --ntasks=56 ## \n#SBATCH -w compute-0-[0,3] \n#SBATCH --time=1-00:00:00 # maximum time for \"normal\" QOS is 1 day\n</code></pre> <pre><code>## for 1 node (e.g. compute-0-1)\n#SBATCH --qos=low ## this is default, so you can ignore it\n#SBATCH --ntasks=16 ## \n#SBATCH -w compute-0-1\n#SBATCH --time=7-00:00:00 # maximum time for \"low\" QOS is 7 days\n</code></pre></p> <p>Warning</p> <p>Please note that currently compute-0-1 has NOT equipped with 10 G adapter, so for distributed MPI parallel jobs, you can not use it.</p>"},{"location":"docs/jobs/running_mpi_jobs/","title":"Running MPI jobs","text":"<p>To run MPI job, you should load OpenMPI module as an e.g.:</p> <pre><code>module load OpenMPI\n</code></pre> <p>You can press tab button twice to see the available versions. See ...</p> <p>This loads the default OpenMPI module and define the environment variable <code>OMPI_MCA_btl=self,vader,tcp</code>. . There are also other versions if you need any other. To search for them run <code>module spider OpenMPI</code>. </p> <p>There are several ways of launching an MPI application within a SLURM allocation, e.g. <code>srun</code>, <code>mpirun</code>, <code>mpiexec</code>. Unfortunately, the best way to launch your program depends on the MPI implementation (and possibly your application), and choosing the wrong command can severely affect the efficiency of your parallel run.  What we recommend is the following:</p> <pre><code>mpirun -np $SLURM_NTASKS your_code &amp;&gt; log.out\n</code></pre>"},{"location":"docs/jobs/slurm/","title":"SLURM Workload Manager","text":"<p>SLURM is the workload manager and job scheduler for Scicluster. The main function of SLURM is to allocate resources within the cluster to its users. Resource management may include managing nodes, sockets, cores, and hyper-threads. In addition, resource allocation based on the topology, software licenses and generic resources such as GPUs can be managed by SLURM.</p> <p>Each job has two parts:</p> <ul> <li>Resource requests: describe the amount of computing resource (CPUs, memory, expected run time, etc.) that the job will need to successfully run.</li> <li>Job steps: describe individual tasks that must be executed into a job. You can execute a job step with the SLURM command <code>srun</code>. A job can has one or more steps, each consisting in one or more tasks each using one or more CPU, GPU, etc.</li> </ul> <p>There are two ways of starting jobs with SLURM; either interactively with <code>srun</code> or as a script with <code>sbatch</code> commands.</p> <p>Interactive jobs are a good way to test your setup before you put it into a script or to work with interactive applications like python. You immediately see the results and can check if all parts behave as you expect. See interactive section for more details.</p> <p>Resources managed by SLURM</p> <ul> <li> <p>Nodes: Node is a computing instance with one or more cores, memory and local storage. Typically, one IP address is assigned to a compute node.</p> </li> <li> <p>Boards: A physical motherboard which contains one or more of each of Socket, Memory bus and PCI bus.</p> </li> <li> <p>Sockets: The receptacle on the motherboard for a physical processor. Depending on the configuration, each socket may contain one or more cores (depending on the processor architecture).</p> </li> <li> <p>Cores: A complete isolated set of registers, Arithmetic Logic Units and queues to execute a program.</p> </li> <li> <p>HyperThreads: Within each physical core, the operating system is able to address two virtual cores to increase the number of independent instruction sets processed.</p> </li> <li> <p>Memory: Memory is made of capacitors and semiconductors to store information for immediate access.</p> </li> <li> <p>Topology guide: To optimize the job performance, SLURM can be configured to topology-aware resource allocation. Currently, it supports 3D topology and hierarchical topology. The default behavior is to consider all the nodes as a one-dimensional array.</p> </li> <li> <p>License guide: SLURM also assists with license management by assigning available licenses to jobs at the time of scheduling. If the relevant license is not available, the job will not be executed and will remain in the pending state.</p> </li> </ul> <p> Ref</p>"},{"location":"docs/jobs/slurm/#slurm-parameter","title":"SLURM Parameter","text":"<p>SLURM supports a multitude of different parameters. This enables you to effectively tailor your script to your need when using Scicluster but also means that it is easy to be confused and waste your time and quota.</p> <p>The following parameters can be used as command line parameters with <code>sbatch</code> and <code>srun</code> or in job script, see job script examples. To use these parameters in a job script, start a newline with <code>#SBTACH</code> directive followed by the parameter. Replace &lt;....&gt; with the value you want, e.g. <code>--job-name=test-job</code>. The following tables show only the most useful ones.</p>"},{"location":"docs/jobs/slurm/#general-parameters","title":"General parameters","text":"Parameter Function <code>--job-name=&lt;name&gt;</code> or <code>-J &lt;name&gt;</code> Job name to be displayed by for example the <code>squeue</code> command <code>--output=&lt;path&gt;</code> or <code>-o &lt;name&gt;</code> Path to the file where the job output is written to <code>--error=&lt;path&gt;</code> or <code>-e &lt;name&gt;</code> Path to the file where the job error is written to <code>--mail-type=&lt;type&gt;</code> Turn on mail notification; type can be one of BEGIN, END, FAIL, REQUEUE or ALL <code>--mail-user=&lt;email_address&gt;</code> Email address to send notifications to"},{"location":"docs/jobs/slurm/#requesting-resources-parameters","title":"Requesting Resources parameters","text":"Parameter Function <code>--time=&lt;d-hh:mm:ss&gt;</code> Time limit for job. Job will be killed by SLURM after time has run out. Format days-hours:minutes:seconds <code>--nodes=&lt;num_nodes&gt;</code> or <code>-N</code> Number of nodes. Multiple nodes are only useful for jobs with distributed-memory (e.g. MPI). <code>--mem=&lt;MB&gt;</code> Memory (RAM) per node. Number followed by unit prefix <code>K|M|G|T</code>, e.g. 16G <code>--mem-per-cpu=&lt;MB&gt;</code> Memory (RAM) per requested CPU core. This option with the value of 512 M is set as the default for all partitions. <code>--ntasks=&lt;num_procs&gt;</code> or <code>-n</code> Number of processes. Useful for MPI jobs. <code>--ntasks-per-node=&lt;num_procs&gt;</code> Number of processes per node. Useful for MPI jobs. Maximum number is node dependent (number of cores) <code>--cpus-per-task=&lt;num_threads&gt;</code> or <code>-c</code> CPU cores per task. For OpenMP (i.e. shared memory) or hybrid OpenMP/MPI use one. Should be equal to the number of threads. <code>--exclusive</code> Job will not share nodes with other running jobs. You will be charged for the complete nodes even if you asked for less."},{"location":"docs/jobs/slurm/#accounting-parameters","title":"Accounting parameters","text":"<p>See also partitions.</p> Parameter Function <code>--account=&lt;name&gt;</code> Project (not user) account the job should be charged to. <code>--partition=&lt;name&gt;</code> or <code>-p</code> Partition/queue in which o run the job. <code>--qos=&lt;...&gt;</code> The quality of service requested; can be low, normal or high"},{"location":"docs/jobs/slurm/#advanced-job-control-parameters","title":"Advanced Job Control parameters","text":"Parameter Function <code>--array=&lt;indexes&gt;</code> Submit a collection of similar jobs, e.g. <code>--array=1-10</code>. (sbatch command only). See official SLURM documentation. <code>--dependency=&lt;state:jobid&gt;</code> Wait with the start of the job until specified dependencies have been satisfied. E.g. <code>--dependency=afterok:123456</code>"},{"location":"docs/jobs/slurm/#settings-for-openmp-and-mpi-jobs","title":"Settings for OpenMP and MPI jobs","text":""},{"location":"docs/jobs/slurm/#single-node-jobs","title":"Single node jobs","text":"<p>For applications that are not optimized for HPC (high performance computing) systems like simple python or R scripts and a lot of software which is optimized for desktop PCs.</p>"},{"location":"docs/jobs/slurm/#simple-applications-and-scripts","title":"Simple applications and scripts","text":"<p>Many simple tools and scripts are not parallelized at all and therefore won't profit from more than one core.</p> Parameter Function <code>--nodes=1</code> Start a job on only one node <code>--ntasks=1</code> One task is requested <code>--mem=&lt;MB&gt;</code> Memory (RAM) for the job. Number followed by unit prefix, e.g. 16G <p>If you are unsure if your application can benefit from more cores try a higher number and observe the load of your job. If it stays at approximately one there is no need to ask for more than one.</p>"},{"location":"docs/jobs/slurm/#openmp-applications","title":"OpenMP applications","text":"<p>OpenMP (Open Multi-Processing) is a multiprocessing library which is often used for programs on shared memory systems. Shared memory describes systems that share the memory between all processing units (cores), so that each process can access all data on that system.</p> Parameter Function <code>--nodes=1</code> Start a parallel job for a shared memory system on only one node <code>--ntasks-per-node=1</code> For OpenMP, only one task is necessary <code>--cpus-per-task=&lt;num_threads&gt;</code> Number of threads (CPU cores) to use <code>--mem=&lt;MB&gt;</code> Memory (RAM) for the job. Number followed by unit prefix, e.g. 16G"},{"location":"docs/jobs/slurm/#multiple-node-jobs-mpi","title":"Multiple node jobs (MPI)","text":"<p>For MPI applications.</p> <p>Depending on the frequency and bandwidth demand of your setup, you can either just start a number of MPI tasks or request whole nodes. While using whole nodes guarantees a lower latency and higher bandwidth it usually results in a longer queuing time compared to cluster wide job. With the latter the SLURM manager can distribute your task across all nodes of Scicluster and utilize otherwise unused cores on nodes which for example run a 6 core job on a 8 core node. This usually results in shorter queuing times but slower inter-process connection speeds.</p>"},{"location":"docs/jobs/slurm/#to-use-whole-nodes","title":"To use whole nodes","text":"Parameter Function <code>--nodes=&lt;num_nodes&gt;</code> Start a parallel job for a distributed memory system on several nodes <code>--ntasks-per-node=&lt;num_procs&gt;</code> Number of (MPI) processes per node. Maximum number depends on node type <code>--cpus-per-task=1</code> Use one CPU core per task. <code>--exclusive</code> Job will not share nodes with other running jobs. You don't need to specify memory as you will get all available on the node."},{"location":"docs/jobs/slurm/#cluster-wide","title":"Cluster wide","text":"Parameter Function <code>--ntasks=&lt;num_procs&gt;</code> Number of (MPI) processes in total. Equals to the number of cores <code>--mem-per-cpu=&lt;MB&gt;</code> Memory (RAM) per requested CPU core. Number followed by unit prefix, e.g. 1G"},{"location":"docs/jobs/slurm/#scalability","title":"Scalability","text":"<p>You should run a few tests to see what is the best fit between minimizing runtime and maximizing your allocated cpu-quota. That is you should not ask for more CPUs for a job than you really can utilize efficiently. Try to run your job on 1, 2, 4, 8, 16, etc., cores to see when the runtime for your job starts tailing off. When you start to see less than 30% improvement in runtime when doubling the cpu-counts you should probably not go any further.</p>"},{"location":"docs/jobs/slurm/#job-related-environment-variables","title":"Job related environment variables","text":"<p>Here we list some environment variables that are defined when you run a job script.  This is not a complete list. Please consult the SLURM documentation for a complete list.</p> <p>Job number:</p> <pre><code>SLURM_JOBID\nSLURM_ARRAY_TASK_ID  # relevant when you are using job arrays\n</code></pre> <p>List of nodes used in a job:</p> <pre><code>SLURM_NODELIST\n</code></pre> <p>Submit directory (this is the directory where you have sbatched your job):</p> <pre><code>SUBMITDIR\nSLURM_SUBMIT_DIR\n</code></pre> <p>Default number of threads:</p> <pre><code>OMP_NUM_THREADS=1\n</code></pre> <p>Task count:</p> <pre><code>SLURM_NTASKS\n</code></pre>"},{"location":"docs/parallel_computing/intro/","title":"Parallel Computing","text":""},{"location":"docs/softwares/containers/","title":"Which software is installed on Scicluster","text":"<p>The easiest way to check which software and versions available is to use the  <code>module</code> command. List all software available::</p> <p>module avail</p> <p>List all version of a specific software::</p> <p>module avail software-name</p>"},{"location":"docs/softwares/modules/","title":"Software Module Scheme","text":"<p>Since a HPC cluster is shared among many users, and also holds a significant size in contrast to most desktop computers, the amount of installed software spans many applications in many different versions. It is not possible (nor desirable) to use them all at the same time, since different versions of the same application may conflict with each other. Therefore, it is practical to provide the production environment, outside of the application itself. This is done using a set of instructions and variable settings that are specific for the given application called an application module. This also simplifies control of which application versions are available in a specific session.</p> <p>The main command for using this system is the module command. You can find a list of all its options by typing:</p> <pre><code>module --help\n</code></pre>"},{"location":"docs/softwares/modules/#which-modules-are-currently-loaded","title":"Which modules are currently loaded?","text":"<p>To see the modules currently active in your session, use the command:</p> <pre><code>module list\n</code></pre>"},{"location":"docs/softwares/modules/#which-modules-are-available","title":"Which modules are available?","text":"<p>In order to see a complete list of available modules, issue the command:</p> <pre><code>module av\n</code></pre>"},{"location":"docs/softwares/modules/#how-to-load-a-module","title":"How to load a module","text":"<p>In order to make, for instance, the openmpi (default version) available, issue the command::</p> <pre><code>module load OpenMPI\n</code></pre> <p>This will load OpenMPI/4.1.1-GCC-10.3.0 and its dependencies.  \u00a0</p>"},{"location":"docs/softwares/modules/#how-to-unload-a-module","title":"How to unload a module","text":"<pre><code>module unload OpenMPI\n</code></pre>"},{"location":"docs/softwares/modules/#search-in-available-modules","title":"Search in available modules","text":"<p>To search for <code>GGG</code> modules as an example:</p> <pre><code>module spider gcc\n</code></pre> <p>Note the <code>spider</code> argument is case-insensitive.</p> <p>The <code>ml</code> alias</p> <p>Module system provides different commands for working with installed softwares/libraries. Please note we can use the <code>ml</code> alias with slightly different syntax, for rapid typing.</p> <p>Module names auto-completion</p> <p>The <code>module</code> command supports auto-completion, so you can just start typing the name of a module, and press Tab to let the shell automatically complete the module name and/or version.</p> <p>These commands and more can be summarized as:</p> Module command Short version Description <code>module avail</code> <code>ml av</code> List available software <code>module load OpenBLAS</code> <code>ml OpenBLAS</code> Load a module to use the associated software <code>module load GCC/12.3.0</code> <code>ml GCC/12.3.0</code> Load specific version of a module <code>module unload Siesta</code> <code>ml -Siesta</code> Unload a module <code>module spider fftw</code> <code>ml spider fftw</code> Search for particular library/software (here <code>FFTW</code>). Search is done case-insensitively. <code>module keyword lapack</code> <code>ml key lapack</code> Search for <code>lapack</code> in module names and descriptions <code>module whatis ScaLAPACK</code> <code>ml whatis ScaLAPACK</code> Display information about the <code>ScaLAPACK</code> module <code>module help ScaLAPACK</code> <code>ml help ScaLAPACK</code> Display module specific help <code>module purge</code> <code>ml purge</code> Remove all modules <code>module save foo</code> <code>ml save foo</code> Save the state of all loaded modules in a collection named <code>foo</code> <code>module restore foo</code> <code>ml restore foo</code> Restore the state of saved modules from the <code>foo</code> collection"},{"location":"docs/softwares/python/","title":"Python","text":"<p>When you first log in to the cluster, the system python is available but this is almost always not what you want. They are installed in <code>/usr/bin</code> paths and we use them for administration purposes.</p> <p>We have also installed different python versions each compiled by different gcc compilers. Currently they are:</p> <pre><code>Python/2.7.15-fosscuda-2018b\nPython/2.7.18-GCCcore-9.3.0\nPython/2.7.18-GCCcore-10.2.0\nPython/2.7.18-GCCcore-10.3.0-bare\nPython/3.8.6-GCCcore-10.2.0\nPython/3.9.5-GCCcore-10.3.0-bare\nPython/3.9.5-GCCcore-10.3.0\nPython/3.11.3-GCCcore-12.3.0\n</code></pre>"},{"location":"docs/softwares/python/#anaconda","title":"Anaconda","text":"<p>We have installed the Anaconda Python distribution as replacement to the system Python. Anaconda provides many additional packages which are ideal for scientific computing.</p> <p>To use Anaconda, We first remove all the loaded modules</p> <pre><code>ml purge\n</code></pre> <p>Then load the Anaconda3</p> <pre><code>ml Anaconda3\n</code></pre> <p>You can use tab completion to see what versions are available. To see all the pre-installed Anaconda packages and their versions use the <code>conda list</code> command:</p> <pre><code>[testuser1@sci ~]$ conda list\n# packages in environment at /home/modules/software/Anaconda3/2024.02-1:\n#\n# Name                    Version                   Build  Channel\n_anaconda_depends         2024.02             py311_mkl_1  \n_libgcc_mutex             0.1                        main  \n_openmp_mutex             5.1                       1_gnu  \nabseil-cpp                20211102.0           hd4dd3e8_0  \naiobotocore               2.7.0           py311h06a4308_0  \naiohttp                   3.9.3           py311h5eee18b_0  \naioitertools              0.7.1              pyhd3eb1b0_0  \naiosignal                 1.2.0              pyhd3eb1b0_0  \nalabaster                 0.7.12             pyhd3eb1b0_0  \naltair                    5.0.1           py311h06a4308_0  \nanaconda-anon-usage       0.4.3           py311hfc0e8ea_100  \nanaconda-catalogs         0.2.0           py311h06a4308_0  \nanaconda-client           1.12.3          py311h06a4308_0  \nanaconda-cloud-auth       0.1.4           py311h06a4308_0  \nanaconda-navigator        2.5.2           py311h06a4308_0  \nanaconda-project          0.11.1          py311h06a4308_0  \nanyio                     4.2.0           py311h06a4308_0  \naom                       3.6.0                h6a678d5_0  \nappdirs                   1.4.4              pyhd3eb1b0_0  \narchspec                  0.2.1              pyhd3eb1b0_0  \nargon2-cffi               21.3.0             pyhd3eb1b0_0  \nargon2-cffi-bindings      21.2.0          py311h5eee18b_0  \narrow                     1.2.3           py311h06a4308_1  \narrow-cpp                 14.0.2               h374c478_1  \nastroid                   2.14.2          py311h06a4308_0  \nastropy                   5.3.4           py311hf4808d0_0\n...\n</code></pre> <p>If we run python:</p> <pre><code>[testuser1@sci ~]$ python\nPython 3.11.7 (main, Dec 15 2023, 18:12:31) [GCC 11.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt;\n</code></pre> <p>The Anaconda Python distribution is system software. This means that you can use any of its packages but you cannot make any modifications to them (such as an upgrade) and you cannot install new ones in their location. You can, however, install whatever packages you want in your home directory in custom environments. The two most popular package managers for installing Python packages are conda and pip.</p> <p>Conda enables you to easily install complex packages and software. Creating multiple environments enables you to have installations of the same software in different versions or incompatible software collections at once. You can easily share a list of the installed packages with collaborators or colleagues, so they can setup the same environment in a matter of minutes.</p> <p>Unlike pip, conda serves as both a package and environment manager. It is not limited to a single programming language, supporting packages for Python, R, Fortran, and more. Conda primarily uses the main channel of Anaconda Cloud for installations, but it can also access other channels like bioconda, intel, r, and conda-forge. It always installs pre-compiled binary files, which often offer better performance by utilizing Intel MKL. Below is an example of creating an environment and installing packages in it:</p> <pre><code>ml purge\nml Anaconda3/2024.02-1\nsource $EBROOTANACONDA3/etc/profile.d/conda.sh\nconda create --name myenv &lt;package-1&gt; &lt;package-2&gt; ... &lt;package-N&gt;\nconda activate myenv\n</code></pre> <p>Home disk quota</p> <p>Installing python packages can simply make you run out of your home disk quota. So we strongly recommend to move your <code>.conda</code> folder to the work directory.</p> <pre><code>cd ~\nmkdir -p /work8/$USER/.conda\nln -s /work8/$USER/.conda .\n</code></pre> <p>As an example let us install the yt package:</p> <pre><code>conda create --name myproject yt\n</code></pre> <p>After a few seconds, it tell us it want to get and install many packages (~ 76 MB) including <code>python-3.11.9</code>. As the default python version of the loaded Anaconda module is <code>3.11.7</code> and the python minor version is not important for installing <code>yt</code> we decide to explicitly determine python version to reduce downloading packages:</p> <pre><code>conda create --name myproject yt python=3.11.7\n</code></pre> <p>Now the download size is decreased to ~ 43 MB. To activate and test:</p> <pre><code>conda activate myproject\nyt --help\n</code></pre> <p>Install the environment in a specific path</p> <p>If we want to install the conda environment in another directory than our home, we can add <code>--prefix PATH</code>. This enables multiple users of a project to share the conda environment by installing it into their project folder instead of the users home</p> <pre><code>conda create --prefix /work8/$USER/envs/myproject yt python=3.11.7\n</code></pre>"},{"location":"docs/softwares/python/#daily-usage","title":"Daily usage","text":"<p>To load this environment we have to use the following commands either on the command line (by assigning an interactive job) or in our job script:</p> <pre><code>ml purge\nml Anaconda3\nsource $EBROOTANACONDA3/etc/profile.d/conda.sh\nconda activate myproject\n</code></pre> <p>Then we can use all software as usual.</p> <p>To deactivate the current environment:</p> <p>conda deactivate</p> <p>If we need to install additional software or packages, we can search for it with:</p> <pre><code>conda search SOMESOFTWARE --channel conda-forge\n</code></pre> <p>and install it with:</p> <pre><code>conda install -n myproject SOMESOFTWARE\n</code></pre> <p>To see installed packages:</p> <pre><code>conda list\n</code></pre> <p>To list available environments:</p> <pre><code>conda env list\n</code></pre> <p>To remove \"myproject\" environment:</p> <pre><code>conda remove --name myproject --all\n</code></pre> <p>If the python package we are looking for is not available in conda we can usually use <code>pip</code> from within a conda environment to install additional python packages:</p> <p><pre><code>pip install package_name\n</code></pre> See also the pip docs.</p> <p>To update a single package with conda:</p> <pre><code>conda update -n myproject package_name\n</code></pre> <p>or to update all packages:</p> <pre><code>conda update -n myproject --all\n</code></pre> <p>You can find the original documentation at </p>"},{"location":"docs/softwares/python/#share-your-environment","title":"Share your environment","text":"<p>To export a list of all packages/programs installed with conda  in a certain environment (in this case \"myproject\"):</p> <pre><code>conda list --explicit --name myproject &gt; package-list.txt\n</code></pre> <p>To setup a new environment (let's call it \"newproj\") from an exported package list:</p> <pre><code>conda create --name newproj --file package-list.txt\n</code></pre> <p>For more details, please see Managing packages and Managing environments.</p>"},{"location":"docs/softwares/python/#using-python-in-interactive-jobs","title":"Using python in interactive jobs","text":"<p>When we want to use python interactively for a time longer than just a short test, we should submit an interactive job. Before running our code, we should setup the environment as explained above.</p>"},{"location":"docs/softwares/python/#using-jupyter-lab","title":"Using jupyter Lab","text":"<p>To use jupyter notebook submit an interactive job and setup your environment, then in a node that is assigned to us (e.g. compute-0-0), we run</p> <pre><code>jupyter lab --no-browser --port=8888\n</code></pre> <p>This will start jupyter and print some information (including an address where the jupyter is running at)</p> <p>Then on the frontend node we run</p> <pre><code>ssh -NL 8888:localhost:8888 compute-0-0\n</code></pre> <p>and in our computer (one that we used to connect to the frontend) run</p> <pre><code>ssh -NL 8888:localhost:8888 your_username@login-node\n</code></pre> <p>Finally we go to the address where the jupyter is running in our web browser, e.g.</p> <pre><code>http://localhost:8888/?token=14ba92d6b0529c3d748b03e31542f988ee3d10b147b7c3f0\n</code></pre>"},{"location":"docs/softwares/python/#using-python-for-long-time-jobs","title":"Using python for long time jobs","text":"<p>For longer usage it will be better to submit a batch script. This could be like</p> <p><pre><code>#!/bin/bash\n#SBATCH -J jupyter\n#SBATCH --partition long\n#SBATCH --nodes=1\n#SBATCH --ntasks=1\n#SBATCH --output=\"stdout_jup.txt\"\n#SBATCH --error=\"stderr_jup.txt\"\n#SBATCH --mem-per-cpu=1000\n#SBATCH --time=7-0:0:0\nulimit -s unlimited\ncd $SLURM_SUBMIT_DIR\nml purge\nml Anaconda3\nsource /home/modules/software/Anaconda3/2020.02/etc/profile.d/conda.sh\nconda activate base\n\npython ./your_python_script.py &gt;&amp; out    \n</code></pre> or for using jupyter, replace the last line with</p> <pre><code>jupyter notebook --no-browser --port=8888 &gt;&amp; out\n</code></pre> <p>and repeat the ssh tunneling as explained above.</p>"},{"location":"docs/softwares/softwares/","title":"Which software is installed on Scicluster","text":"<p>The easiest way to check which software and versions available is to use the  <code>module</code> command.</p> <p>List all software available:</p> <pre><code>module avail\n</code></pre> <p>See the next section Software Module Scheme for details.</p>"},{"location":"docs/softwares/softwares/#conda","title":"Conda","text":"<p>Many software packages, especially if they are python based, can be easily installed using the Conda package manager.</p> <p>A small tutorial can be found in the python section of this documentation.</p>"},{"location":"docs/softwares/apps/","title":"Application guides","text":"<p>In this section we describe how you can use the installed softwares and application.</p>"},{"location":"docs/softwares/apps/astrophysics/BHAC/BHAC/","title":"BHAC","text":"<p>BHAC (the Black Hole Accretion Code) is a multidimensional general relativistic magnetohydrodynamics code based on the MPI-AMRVAC framework. BHAC solves the equations of ideal general relativistic magnetohydrodynamics in one, two or three dimensions on arbitrary stationary space-times, using an efficient block based approach.</p>"},{"location":"docs/softwares/apps/astrophysics/BHAC/BHAC/#installation","title":"Installation","text":"<pre><code>mkdir codes\ncd codes\ngit clone https://gitlab.itp.uni-frankfurt.de/BHAC-release/bhac.git\n\necho 'export BHAC_DIR=$HOME/codes/bhac' &gt;&gt; ~/.bashrc\necho 'PATH=\"$BHAC_DIR:$BHAC_DIR/tools:./:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre>"},{"location":"docs/softwares/apps/astrophysics/BHAC/BHAC/#making-the-code","title":"Making the code","text":"<pre><code>mkdir /work8/$USER/bhac_runs\ncd /work8/$USER/bhac_runs\ncp -r $BHAC_DIR/tests/rmhd/shockTube ./\ncd shockTube\nml OpenMPI/4.1.2-GCC-11.2.0\n$BHAC_DIR/setup.pl -d=13 -phi=3 -z=2 -g=12 -p=rmhd -eos=gamma -nf=0 -arch=gfortran10 -coord=cart\nmake\n</code></pre>"},{"location":"docs/softwares/apps/astrophysics/BHAC/BHAC/#run-a-quick-test","title":"Run a quick test","text":"<pre><code>salloc -p para -n 4 --ntasks-per-core=1 -w compute-0-0 --time=01:00:00\ncd /work8/$USER/bhac_runs/\ncd shockTube\nmkdir output\nml OpenMPI/4.1.2-GCC-11.2.0\nmpirun -n 4 ./bhac -i amrvac1D.par &gt;output/out\n</code></pre>"},{"location":"docs/softwares/apps/astrophysics/GADGET/GADGET-v4/","title":"GADGET v4","text":""},{"location":"docs/softwares/apps/astrophysics/GIZMO/GIZMO/","title":"GIZMO","text":"<p>.. _GIZMO:</p> <p>==================================================================== GIZMO, a flexible, massively-parallel, multi-physics simulation code ====================================================================</p>"},{"location":"docs/softwares/apps/astrophysics/GIZMO/GIZMO/#general-information","title":"General Information","text":""},{"location":"docs/softwares/apps/astrophysics/GIZMO/GIZMO/#description","title":"Description","text":"<p>GIZMO lets you solve the fluid equations using a variety of different methods -- whatever is best for the problem at hand. It introduces new Lagrangian Godunov-type methods that allow you to solve the fluid equations with a moving particle distribution that is automatically adaptive in resolution and avoids the advection errors, angular momentum conservation errors, and excessive diffusion problems that limit the applicability of \u201cadaptive mesh\u201d (AMR) codes, while simultaneously avoiding the low-order errors inherent to simpler methods like smoothed-particle hydrodynamics (SPH). Meanwhile, self-gravity is solved fast, with fully-adaptive gravitational softenings. And the code is massively parallel \u2014 it has been run on everything from a Mac laptop to &gt;1 million CPUs on national supercomputers.</p> <p>.. toctree::    :maxdepth: 1    :titlesonly:</p> <p>firsttime_gizmo.rst</p>"},{"location":"docs/softwares/apps/astrophysics/GIZMO/GIZMO/#online-info","title":"Online info","text":"<ul> <li><code>Homepage &lt;http://www.tapir.caltech.edu/~phopkins/Site/GIZMO.html&gt;</code>_ </li> <li><code>Documentation &lt;http://www.tapir.caltech.edu/~phopkins/Site/GIZMO_files/gizmo_documentation.html&gt;</code>_</li> </ul>"},{"location":"docs/softwares/apps/astrophysics/GIZMO/GIZMO/#gizmo-on-scicluster","title":"GIZMO on Scicluster:","text":""},{"location":"docs/softwares/apps/astrophysics/GIZMO/GIZMO/#usage","title":"Usage","text":"<p>TBA</p>"},{"location":"docs/softwares/apps/astrophysics/GIZMO/firsttime_gizmo/","title":"Firsttime gizmo","text":"<p>.. _first_time_gizmo:</p> <p>================================= First time you run GIZMO =================================</p> <p>TBA</p>"},{"location":"docs/softwares/apps/math-stat/Mathematica/","title":"Mathematica","text":"<p>Wolfram Mathematica is a modern technical computing system spanning most areas of technical computing \u2014 including neural networks, machine learning, image processing, geometry, data science, visualizations, and others. The system is used in many technical, scientific, engineering, mathematical and computing fields.</p> <ul> <li>Homepage</li> <li>Documentation</li> </ul>"},{"location":"docs/softwares/apps/math-stat/Mathematica/#mathematica-on-scicluster","title":"Mathematica on Scicluster","text":""},{"location":"docs/softwares/apps/math-stat/Mathematica/#interactive-session","title":"Interactive Session","text":"<p>Request an Interactive Job with X11 forwarding ++++++++++++++++++++++++++++++++++++++++++++++</p> <p>Login to the frontend ::</p> <p>ssh -Y username@login-node</p> <p>To run Mathematica interactively, you need to request an interactive session on a compute node. See :doc:<code>/jobs/interactive</code>.</p> <p>After requesting an interactive job for example on <code>compute-0-3</code> node, run in another terminal ::</p> <p>ssh -Y compute-0-3</p> <p>Usage +++++</p> <p>To launch Mathematica in your above mentioned terminal, you will first need to make sure you have the correct module loaded. You can search for all available Mathematica versions. ::</p> <p>module avail Mathematica</p> <p>Load the appropriate module file. For example, to run version 12.3. ::</p> <p>module load Mathematica/12.3.0</p> <p>Once you have the appropriate module loaded in an interactive job, start Mathematica. The <code>&amp;</code> will put the program in the background so you can continue to use your terminal session. ::</p> <p>Mathematica &amp;</p>"},{"location":"docs/softwares/apps/math-stat/Mathematica/#batch-mode","title":"Batch mode","text":"<p>Serial job ++++++++++</p> <p>Consider this simple one line script (hello_world.nb) ::</p> <pre><code>Print[\"Hello, World.\"]\n</code></pre> <p>Below is a Slurm script (job.slurm) appropriate for a serial Mathematica job: ::</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=myjob         # create a short name for your job\n#SBATCH --nodes=1                # node count\n#SBATCH --ntasks=1               # total number of tasks across all nodes\n#SBATCH --cpus-per-task=1        # cpu-cores per task (&gt;1 if multi-threaded tasks)\n#SBATCH --mem-per-cpu=4G         # memory per cpu-core (4G per cpu-core is default)\n#SBATCH --time=00:01:00          # total run time limit (HH:MM:SS)\n\nmodule purge\nmodule load Mathematica/12.3.0\n\nmath -run &lt; hello_world.nb &amp;&gt; output\n</code></pre> <p>Submit the job with: ::</p> <pre><code>sbatch job.slurm\n</code></pre> <p>Parallel job ++++++++++++</p> <p>Consider this simple parallel Mathematica script (simple_par.nb): ::</p> <pre><code>Print[ParallelEvaluate[$KernelID]]\nPrint[ParallelEvaluate[$ProcessID]]\n</code></pre> <p>which can be submitted as a parallel job, using this script (job.slurm): ::</p> <pre><code>#!/bin/bash\n#SBATCH --job-name=myjob         # create a short name for your job\n#SBATCH --nodes=1                # node count\n#SBATCH --ntasks=1               # total number of tasks across all nodes\n#SBATCH --cpus-per-task=4        # cpu-cores per task (&gt;1 if multi-threaded tasks)\n#SBATCH --mem-per-cpu=4G         # memory per cpu-core (4G per cpu-core is default)\n#SBATCH --time=00:01:00          # total run time limit (HH:MM:SS)\n\nmodule purge\nmodule load Mathematica/12.3.0\n\nmath -run &lt; simple_par.nb &amp;&gt; output\n</code></pre> <p>You can see :ref:<code>job_script_examples</code> for more advanced examples.</p>"},{"location":"docs/storage/storage/","title":"Storage","text":""},{"location":"docs/storage/storage/#available-file-system","title":"Available file system","text":"<p>Scicluster currently has four special storage file systems:</p> <ul> <li>Network shared (NFS) home area:            <code>/home</code>        (RAID 1, ~ 620 GB, NAS aware SATA3 disks)</li> <li>Network shared (NFS) work8 area:           <code>/work8</code> (8 TB SATA3 data center special disk)</li> <li>Network shared (NFS) fortitude8 area:      <code>/fortitude8</code> (8 TB SATA3 data center special disk)</li> <li>Network shared (NFS) gratitude8 area:      <code>/gratitude8</code> (8 TB SATA3 data center special disk)</li> <li>Local scratch area on each node:           <code>/state/partition1</code>  (soft linked to <code>/scratch1</code>) (1.2 TB SAS disks)</li> </ul>"},{"location":"docs/storage/storage/#home-area","title":"Home area","text":"<p>This file system is for user home directories on Scicluster. It is not on a seperate hard disk, so please do not use it for big files at all. <code>/home/username</code> is accessible from both the frontend and all the compute nodes. If you need more space, consider using <code>/work8</code> (see below).</p> <p>The home area is for permanent storage only, so please do not use it for temporary storage during production runs at all. Your quota space is ~ 4.5 GB. Your quota file number is 12000 files. All jobs using the home area for output while running, may be killed without any warning.</p>"},{"location":"docs/storage/storage/#work8-area","title":"/Work8 area","text":"<p>This file system could be used for writing the output of MPI parallel jobs that run on more than one node. It could also be used for saving your date that are written on local scratch (see below) spaces in each node. The current quotas for each user on <code>/work8</code> are: 375 GB soft limit and 380 GB hard limit. The quota file number is 45000 files.</p>"},{"location":"docs/storage/storage/#fortitude8-area","title":"/fortitude8 area","text":"<p>Same as the <code>work8</code> disk but you need to contact us for assigning quota.</p>"},{"location":"docs/storage/storage/#gratitude8-area","title":"/gratitude8 area","text":"<p>Same as the /fortitude8.</p>"},{"location":"docs/storage/storage/#scratch-areas","title":"Scratch areas","text":"<ul> <li>In addition, each compute node has a scratch area of 1.2 TB, only locally accessible on each node. This is the area which should be used for serial jobs or parallel jobs that run on just one node. The space is currently accessible as   <code>/state/partition1</code> or <code>/scratch1</code> on each compute node. Scratch spaces are high speed and consist of SAS 10k and 15k disks. Please note that there is no quota limit but all data will be removed automatically after two weeks.</li> </ul>"},{"location":"docs/storage/storage/#quota","title":"Quota","text":"<p>Your quota is shown below the welcome message each one you login to the frontend. You can also see your quota amount by running:</p> <pre><code>quota -vs\n</code></pre> <p>As it is mentioned above, the current quota in Scicluster is:</p> File System Quota File limit /home 4.5 GB 12000 /work8 (/dev/sdc1) 450 GB 45000 /fortitude8 (/dev/sdd1) contact us - /gratitude8 (/dev/sde1) contact us -"},{"location":"docs/web_portal/web_portal/","title":"Web Portal","text":"<p>Note</p> <p>Please replace login-node with the IP provided to you, everywhere in this user guide.</p> <p>Scicluster provides a nice web portal using OnDemand to see and submit jobs, to browse, upload, download and copy files, to work with the terminal in the browser and more interestingly web-based access to the Jupyter that could be run in the compute nodes beautifully.</p>"},{"location":"docs/web_portal/web_portal/#logging-in","title":"Logging in","text":"<p>To login into the portal, you must have already a cluster account. Please connect to the VPN address provided to you, then go to this address in your web browser https://login-node . You may face with a potential security warning. This is because we do not get a registered certificate. This is not important and you could go on. After this part, you should be able to see the welcome page</p> <p></p>"},{"location":"docs/web_portal/web_portal/#preparing-ondemand-folder","title":"Preparing OnDemand Folder","text":"<p>The OnDemand web portal makes a folder in your home directory once you login for the first time and saves its files there. As the home quota is very limited, it is a good practice to move this folder to <code>/work8/your_username</code> and make a link to this now dislocated <code>~/ondemand</code> folder. So do</p> <pre><code>mv ~/ondemand /work8/$USER/ondemand\nln -s /work8/$USER/ondemand ~/ondemand\n</code></pre> <p>Note</p> <p>If you have any problem with the portal, first try to log out and login again. Next, try to clear all cookies for the domain <code>login-node</code>. Finally, try the <code>Help &gt; Restart Web Server</code> link to restart the portal.</p>"},{"location":"docs/web_portal/web_portal/#portal-dashboard","title":"Portal Dashboard","text":"<p>The dashboard has different menus. Here we explain them but not with detail.</p>"},{"location":"docs/web_portal/web_portal/#files","title":"Files","text":"<ul> <li>Home Directory - Here, you can browse, see and edit your files in the frontend node. For editing files, there is a nice web-based editor.</li> <li>/work8/your_username - Your disk space on <code>/work8</code>.</li> </ul> <p>If you have assigned disk space on other storages storages, they should also be appeared in the menu.</p>"},{"location":"docs/web_portal/web_portal/#jobs","title":"Jobs","text":"<ul> <li>Active Jobs - List all and delete your jobs.</li> <li>Job Composer - Start a new job.</li> </ul>"},{"location":"docs/web_portal/web_portal/#clusters","title":"Clusters","text":"<ul> <li>Shell Access - Shell access in your browser.</li> </ul>"},{"location":"docs/web_portal/web_portal/#interactive-apps","title":"Interactive Apps","text":"<ul> <li>Computational containerized Desktops - Start virtual desktops on the HPC (e.g. for plotting your data).</li> <li>Jupyter - Run Jupyter on the HPC and easily connect to it from your browser without setting up any SSH tunnels.</li> </ul>"},{"location":"docs/web_portal/web_portal/#my-interactive-sessions","title":"My Interactive Sessions","text":"<p>See details of your currently running interactive sessions.</p>"},{"location":"docs/web_portal/web_portal/#help","title":"Help","text":"<ul> <li>Restart Web Server - Try this if the portal acts weird before contacting us. The web portal runs a web server per user, so this does not affect any other user.</li> </ul>"},{"location":"docs/web_portal/web_portal/#log-out","title":"Log Out","text":"<ul> <li>Log out of the portal.</li> </ul>"},{"location":"tutorial/","title":"Tutorials","text":""},{"location":"tutorial/#introduction-to-hpc-systems-and-using-scicluster","title":"Introduction to HPC systems and using Scicluster","text":""},{"location":"tutorial/#videos-in-farsi","title":"Videos (in Farsi)","text":"<p>1- Gnu/Linux clusters in general, Scicluster overview and using the available softwares</p> <p>2- Building your softwares, working with Python and installing its packages, all on Scicluster</p> <p>3- Working with Slurm, submitting serial and parallel (OpenMP, MPI and GPU) jobs on Scicluster</p> <p>4- Scicluster web interface and using Jupyter and containers by its help</p>"},{"location":"blog/archive/2024/","title":"2024","text":""},{"location":"blog/category/astrophysics/","title":"astrophysics","text":""},{"location":"blog/category/code-example/","title":"code-example","text":""},{"location":"blog/category/general/","title":"general","text":""}]}